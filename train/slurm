#!/bin/bash
#SBATCH --job-name=mamba       ##作业名称
#SBATCH --partition=bio                  ##作业申请的分区名称
#SBATCH --nodes=1                        ##作业申请的节点数
#SBATCH --ntasks-per-node=8             ##作业申请的每个节点使用的核心数
#SBATCH --account=jxy                    ##用户所在用户组名称
#SBATCH --error=%j.err
#SBATCH --output=%j.out
#SBATCH --gres=gpu:1                    ## GPU Number for use
#SBATCH --exclude=gpu[06-09]

# CURDIR=`pwd`
# rm -rf $CURDIR/nodelist.$SLURM_JOB_ID
# NODES=`scontrol show hostnames $SLURM_JOB_NODELIST`
# for i in $NODES
# do
# echo "$i:$SLURM_NTASKS_PER_NODE" >> $CURDIR/nodelist.$SLURM_JOB_ID
# done
# echo $SLURM_NPROCS
# echo $SLURM_GPUS

source activate mamba

python v1_main.py --model="ipa+egnn" --batch_size=4 --n_layers=6 --d_conv=4 --lr=1e-3 --d_model=256 --d_state=64 --dropout=0.5 --stage1_epochs=300 --ver="v1" --use_cache

# python ./v_pre_train/T_main.py --model="egnn+ipa" --batch_size=8 --lr=1e-3 --stage1_epochs=150

# python ./v_pre_train/T_main.py --model="egnn" --batch_size=2 --depth=4 --lr=1e-3 --stage1_epochs=150 --ver="egnn_1e-3_traj_noseed_decay_1e-6" --use_cache

# python ./v_pre_train/T_main.py --model="ipa" --batch_size=1 --depth=4 --lr=1e-3 --stage1_epochs=150 --ver="ipa_1e-3_traj_noseed" --use_cache


#egnn调参
# python ./v_pre_train/optuna_tune.py --n_trials 10 --stage1_epochs 20

# python a_pred_Traj_mamba.py
